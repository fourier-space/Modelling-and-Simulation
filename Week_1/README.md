# Week 1 â€“ Floating Point Numbers

## Exercises
1. Install [Wolfram Mathematica](https://www.wolfram.com/siteinfo/).
2. Is 0.1 + 0.2 greater or less than 0.3, does this depend on the size of the floating point representation?
3. Calculate the optimal step size and error for central difference first derivative. How does each quantity compare to the forward difference case?
4. How would you acually calculate sin and cos numerically?
5. Understand and explain how the [Fast inverse square root (Quake 3)](https://en.wikipedia.org/wiki/Fast_inverse_square_root) works. How would it look in 16 bit precision?

## Resources
* [Float Toy](https://evanw.github.io/float-toy/)
* [What Every Computer Scientist Should Know About Floating-Point Arithmetic](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)
* [Fast inverse square root (Quake 3)](https://en.wikipedia.org/wiki/Fast_inverse_square_root)

## More Resources
* https://www.coursera.org/learn/linear-algebra-machine-learning?specialization=mathematics-machine-learning
* https://www.coursera.org/learn/multivariate-calculus-machine-learning?specialization=mathematics-machine-learning
* https://www.linkedin.com/learning/hands-on-start-to-wolfram-mathematica/
